% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/RcppExports.R
\name{FOS}
\alias{FOS}
\title{The Fast and Optimal Support Algorithm

Description}
\usage{
FOS(X, Y, solver_type, use_single_precision = FALSE)
}
\arguments{
\item{X:}{An n x p design matrix.}

\item{Y:}{A 1 x p array representing the predictors}

\item{solver_type:}{The type of iterative solver used internally. Can used
sub-gradient descent methods or coordinate descent, both of which
can use GAPSAFE screening rules or not.}

\item{use_single_precision:}{If set to TRUE double-precision floating point values
will be cast to single-precision. This will result in less memory usable and faster
execution, but may result in numerical precision issues.}
}
\value{
A list containing the results of the regression.
\item{beta}{The coefficients of the regression results}
\item{index}{The number of the grid element where the algorithm stops, in the range 1 - 100 }
\item{lambda}{The regularization parameter that was deemed optimal}
\item{intercept}{Value of the intercept term.}
\item{support}{The estimated support. Enteries will be 0 if the regression coefficient was
zero, and 1 if it was non-zero and signifigant.}
}
\description{
Perform an L1 regularized linear regression using the Fast and Optimal Support
 algorithm.
}
\examples{
library(HDIM)

dataset <- matrix(rexp(200, rate=.1), ncol=20)

yinput <- dataset[, 1, drop = FALSE]
xinput <- dataset[, names(dataset) != names(yinput)]

fos_fit <- HDIM::FOS( as.matrix(xinput), as.matrix(yinput), "cd" )
}
\references{
Néhémy Lim, Johannes Lederer (2016)
  \emph{Efficient Feature Selection With Large and High-dimensional Data},
     \url{https://arxiv.org/abs/1609.07195}\cr
  \emph{Pre-print via ArXiv}\cr
  \url{https://arxiv.org}\cr
}
\author{
Benjamin J Phillips e-mail:bejphil@uw.edu
}
